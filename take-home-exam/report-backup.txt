\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{cases}
\usepackage{multirow}

\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{cases}
 \usepackage{geometry}
 \usepackage{float}
\usepackage{a4wide}
\usepackage{listings}
\usepackage{url}
\usepackage{graphicx}
\usepackage{algorithm2e}
\graphicspath{ {./images/} }
\usepackage{subfiles}

\usepackage{hyperref}
\usepackage{comment}
\usepackage{textcomp,gensymb}

\usepackage[toc,page]{appendix}

\usepackage[style=ieee, citestyle=numeric-comp, backend=biber]{biblatex}
\addbibresource{mybibliography.bib}

\setlength{\parindent}{0pt}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cases}

% \usepackage[margin=25mm]{geometry}\usepackage{fullpage}

\usepackage{subcaption}
\usepackage{float}


\usepackage{listings}
\usepackage{lmodern}  % for bold teletype font
\usepackage{amsmath}  % for \hookrightarrow
\usepackage{xcolor}   % for \textcolor
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\usepackage{algorithm}
\usepackage{algpseudocode}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
    %\usepackage{showframe} %This line can be used to clearly show the new margins

    \newgeometry{vmargin={30mm}, hmargin={20mm,20mm}}

\title{Take Home Exam SSY316}
\author{Matthew Newson, Erik Norlin}
\date{January 2023}

\begin{document}

\maketitle

\section*{Q1: Principal Component Analysis (PCA) of
Genomes}

\subsection*{1.}
Performing singular value decomposition of the mean centered data set $X$ with individuals as rows and features as columns yields $X=U\Sigma V^T$. The principal components are $U\Sigma \in \mathbb{R}^{995\times 995}$, the principal directions $V\in \mathbb{R}^{10101\times 995}$, and the variances along the diagonal of $\frac{1}{n-1}\Sigma^2 \in \mathbb{R}^{995\times 995}$.

\subsection*{2.}

Figure \ref{fig:q1-2} shows the first two principal components of the data set.
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Q1_2.png}
    \caption{The first two principal components of the data set with labels African Caribbean in Barbados (ACB), African Ancestry in Southwest US (ASW), Esan in Nigeria (ESN), Gambian in Western Division (GWD), Luhya in Webuye (LWK), Mende in Sierra Leone (MSL), and Yoruba in Ibadan (YRI).}
    \label{fig:q1-2}
\end{figure}

\subsection*{3.}

The figure tells us that populations located in Nigeria (ESN and YRI) overlap and the populations located in America (ACB and ASW) overlap somewhat. Populations that do not share the same regions, such as the population in Gambia and in Sierra Leone do not overlap as much. \\

An interpretation of the first two principal components could be that they capture genetic similarities and differences in the populations because populations sharing the same regions tend to cluster together.

\subsection*{4.}

Figure \ref{fig:q1-4} shows the first and third principal components of the data set.
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Q1_4.png}
    \caption{The first and third principal components of the data set with labels males (M) and females (F).}
    \label{fig:q1-4}
\end{figure}

\subsection*{5.}
From the figure we can see that the first and third principal components capture genetic differences in males and females.

\subsection*{6.}

From inspection in Figure \ref{fig:q1-6} it is noticeable that the third principal direction dominantly points in the direction of the dimensions representing nucleobase indices larger than 9500, which could indicate that these nucleobases are responsible for male and female differences.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Q1_6.png}
    \caption{The absolute value of the third principal direction against the nucleobase index.}
    \label{fig:q1-6}
\end{figure}

\newpage
\section*{Q2: Markov Chain Monte Carlo}
\subsection*{1.}

The joint likelihood is

$$
p(\textbf{y},\boldsymbol{\theta}, \boldsymbol{\eta}) = 
p(\boldsymbol{\eta})p(\boldsymbol{\theta}\mid \boldsymbol{\eta})p(\textbf{y}\mid \boldsymbol{\theta})
$$

$$
=p(\mu_{att})p(\mu_{def})p(\tau_{att})p(\tau_{def})\prod_{t=0}^{T=19}p(att_t\mid\mu_{att},\tau_{att})p(def_t\mid\mu_{def},\tau_{def})\prod_{g=0}^{G=379}\prod_{j=0}^{J=1}p(\textbf{y}_{gj}\mid \boldsymbol{\theta}_{gj})
$$

$$
=\mathcal{N}(\mu_{att}\mid0,\tau_1^{-1})\mathcal{N}(\mu_{def}\mid0,\tau_1^{-1})\text{Gam}(\tau_{att}\mid\alpha, \beta)\text{Gam}(\tau_{def}\mid\alpha, \beta)
$$
$$
\cdot\prod_{t=0}^{T=19}\mathcal{N}(att_t\mid\mu_{att},\tau_{att}^{-1})\mathcal{N}(def_t\mid\mu_{def},\tau_{def}^{-1})
$$
$$
\cdot\prod_{g=0}^{G=379}\text{Po}(y_{g0}\mid home+att_{h(g)}-def_{a(g)})\text{Po}(y_{g1}\mid att_{a(g)}-def_{h(g)})
$$

\subsection*{2.}
The Metropolis-Hastings algorithm for sampling from the posterior $p(\boldsymbol{\theta}, \boldsymbol{\eta}\mid \textbf{y})$ is shown in Algorithm \ref{alg:mh}.

\begin{algorithm}
\caption{Metropolis-Hastings}
\label{alg:mh}
\For{i = 1:iterations}{
Sample hyper-priors and priors $\textbf{x}_{s+1}$ from the proposal distribution $\mathcal{N}(\textbf{x}_{s},\sigma^2I)$\\
Compute the probabilities $p(\textbf{x}_{s})$ and $p(\textbf{x}_{s+1})$ given the observed data\\
Compute the acceptance probability $p_A = p(\textbf{x}_{s+1}) / p(\textbf{x}_{s})$\\
Accept the new sample $\textbf{x}_{s} \leftarrow \textbf{x}_{s+1}$ \textbf{if} $u\sim\mathcal{U}(0,1) < p_A$ \\
Save $\textbf{x}_{s}$ every $t$:th iteration and \textbf{if} $i >$ burn in
}
\end{algorithm}

acceptance function?    

\subsection*{3.}


\begin{table}[H]
    \centering
        \caption{Rejection ratio for each parameter setting of thinning $t$ and standard deviation $\sigma$ of the proposal distribution.}
        \begin{tabular}{p{0.04\textwidth}|p{0.05\textwidth}|p{0.05\textwidth}|p{0.05\textwidth}}
            % \toprule
            \multicolumn{3}{c}{}\\
            \toprule
            \toprule
            $t$ \textbackslash \hspace{0.01cm} $\sigma$ & 0.005 & 0.05 & 0.5 \\
            \midrule
            1 &  &  \\
            5 &  & \\
            20 & & \\
            50 & & \\
            
            \bottomrule            
        \end{tabular}
    \label{tab:ce4-0-3}
\end{table}


\newpage
\section*{Q3: Variational Inference (VI) [30 pts]}
\subsection*{3.1 A Review of Vanilla LDA [9 pts]}

1. False, the LDA involves Dirichlet and multinomial distributions and Dirichlet is the conjugate prior of the distribution of the categorical distribution. 

2. True, Variational EM involves maximizing a lower bound on the log-likelihood, and this optimization problem is non-convex in the case of LDA. The E-step of the EM algorithm requires finding the optimal values for the variational parameters, which involves non-convex optimization.

3. T

V = number of words

4. The computational complexity of the mean-field is VI for LDA is O(KDV)

5. The memory complexity of the mean-field is VI for LDA is O()

6. False, it is used for extracting topics from text corpora. 
\subsection*{3.2 More HMMs [21 pts]}

1. \textbf{Variables:}

(a) Observed variables:

For each document, $w_d$ (word sequence).\\

(b) Hidden variables:

For each document $w_d$:
\begin{itemize}
    \item $p_d$: Beta-distributed variable.
    \item $\theta_d$: Dirichlet-distributed variable.
    \item $z_{d1}$: Multinomial-distributed variable for the first word.
    \item $\delta_{di}$: Bernoulli-distributed variable for each subsequent word.
    \item $z_{di}$: Multinomial-distributed variable for each subsequent word.
\end{itemize}

(c) Model parameters to be estimated:

\begin{itemize}
    \item $\alpha$: Dirichlet parameter.
    \item $\beta$: Multinomial parameter.
    \item $\gamma$: Beta parameter.
    \item $T$: Transition matrix among $K$ topics.
\end{itemize}


\newpage
\section*{Q4: QWOP}

\subsection*{3.}
Three methods were implemented to optimize QWOP. The first being uniform random search, the second being gradient descent (GD) with fixed step rate and the last being an evolutionary algorithm (EA). Random search was the first solution that came to mind and was straight forward to implement; in a for loop, pick a random sequence and simulate the plan. The best random search performed was 6 m after 40,000 iterations. GD on the other hand did not do as well as topping at 3 m. Since the objective function consists of 40 variables and is assumably highly non-convex, it makes sense that any given instance of GD will, most likely, quickly converge to a local minimum resulting in poor performance in the game. For this reason, an EA was considered. EAs are incredibly suitable for optimization problems where the objective function is highly non-convex. It consists of a population of randomly initialized individuals (instances) and the ones that yield better performance reproduce with other well performing individuals often leading to better performing offsprings. The EA that was implemented was initialized with 500 individuals and ran for 100 generations. The best performing individual got to almost 8 m, beating random search by roughly 2 m. The corresponding plan is presented in Listing \ref{lst:plan}. \\

\begin{lstlisting}[language=Python, caption={Best plan obtained for QWOP by the EA. Yields a total distance of 7.84 m.}, label={lst:plan}]
plan = [-1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1]
\end{lstlisting}

Furthermore, the initial plan in GD was experimented with in hope to improve GD's performance. Starting GD with the best plans obtained from random search and the EA respectively did however not yield any better performance. GD still converged quickly at around 3 m every time. \\


\newpage
\section*{Appendix}


\begin{lstlisting}[language=Python, caption={Python script for Q1.}, label={lst:Q1}]
import numpy as np
import numpy.linalg as la 
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.decomposition import PCA


def get_most_appearing_char(column):
    return column.value_counts().idxmax()

df = pd.read_csv('p4dataset2023.txt', sep=' ', header=None)
most_appearing_chars = df.apply(get_most_appearing_char, axis=0)
X_arr = df.iloc[:,3:].eq(most_appearing_chars[3:]).astype(int)
X_arr_centered = X_arr - X_arr.mean(axis=0)

U, S, VT = la.svd(X_arr_centered, full_matrices=False)
print('U shape:', U.shape, 'S shape:', S.shape, 'VT shape:', VT.shape)

pca = PCA(n_components=3)
X_pca = pca.fit(X_arr_centered)
XV = X_pca.transform(X_arr_centered)

labels_data = np.array(df.iloc[:,2])
labels = np.unique(labels_data)
colors = ['red', 'blue', 'green', 'yellow','orange', 'purple', 'pink', 'brown']
cdict = {keyword: colors[index] for index, keyword in enumerate(labels)}

fig = plt.figure(figsize=(6,3))
ax = plt.axes()
for label in labels:
    idx = np.where(label == labels_data)
    ax.scatter(XV[idx,0], XV[idx,1], marker='.', c=cdict[label], label=label)
ax.set_xlabel('$v_1$')
ax.set_ylabel('$v_2$')
ax.set_aspect('equal')
ax.legend(loc="lower right") 
fig.tight_layout()
plt.show()

labels_data = np.array(df.iloc[:,1])
labels = np.unique(labels_data)
colors = ['red', 'blue', 'green', 'yellow','orange', 'purple', 'pink', 'brown']
cdict = {keyword: colors[index] for index, keyword in enumerate(labels)}

fig = plt.figure(figsize=(5,3))
ax = plt.axes()
for label in labels:
    idx = np.where(label == labels_data)
    ax.scatter(XV[idx,0], XV[idx,2], marker='.', c=cdict[label], label=label)
ax.set_xlabel('$v_1$')
ax.set_ylabel('$v_3$')
ax.set_aspect('equal')
ax.legend(loc="lower right") 
fig.tight_layout()
plt.show()

fig = plt.figure()
ax = plt.axes() 
ax.plot(np.abs(X_pca.components_[2]), '.')
ax.set_xlabel('Nucleobase index')
ax.set_ylabel('Absolute value of third principal direction')
fig.tight_layout()
plt.show()
\end{lstlisting}



\begin{lstlisting}[language=Python, caption={The implemented methods for optimizing QWOP in Python for Q4.}, label={lst:Q4}]
def crossover(individual1, individual2):
    n_genes = len(individual1)
    crossover_point = np.random.randint(1, n_genes)
    new_individuals = np.zeros((2, n_genes))

    for j in range(n_genes):
        if j < crossover_point:
            new_individuals[0, j] = individual1[j]
            new_individuals[1, j] = individual2[j]
        else:
            new_individuals[0, j] = individual2[j]
            new_individuals[1, j] = individual1[j]

    return new_individuals


def tournament_select(fitness_list, tournament_probability, tournament_size):
    most_fit = 0
    fitness_index = 0
    individual_index = 1

    population_size = len(fitness_list)
    tour_fitness_and_individual = np.zeros((tournament_size, 2))

    for i in range(tournament_size):
        i_tmp = np.random.randint(0, population_size)
        tour_fitness_and_individual[i, fitness_index] = fitness_list[i_tmp]
        tour_fitness_and_individual[i, individual_index] = i_tmp

    tour_fitness_and_individual = tour_fitness_and_individual[tour_fitness_and_individual[:, fitness_index].argsort()[::-1]]

    while True:
        r = np.random.rand()
        if r < tournament_probability:
            selected_individual_index = int(tour_fitness_and_individual[most_fit, individual_index])
            return selected_individual_index
        else:
            remaining_participants = tour_fitness_and_individual.shape[0]
            if remaining_participants > 1:
                tour_fitness_and_individual = np.delete(tour_fitness_and_individual, most_fit, axis=0)
            else:
                selected_individual_index = int(tour_fitness_and_individual[most_fit, individual_index])
                return selected_individual_index

                
def decode_chromosome(chromosome, number_of_variables, maximum_variable_value):
    x = np.zeros(number_of_variables)
    n_genes = len(chromosome)
    variable_length = int(np.floor(n_genes / number_of_variables))
    i_gene = 0
    maximum_variable_value = np.abs(maximum_variable_value)

    for i in range(number_of_variables):
        x[i] = 0.0
        for j in range(0, variable_length):
            x[i] += 2**-j * chromosome[i_gene]
            i_gene += 1

        # x[i] = -maximum_variable_value + ((2 * maximum_variable_value * x[i]) / (1 - 2**(-variable_length)))
        x[i] = -maximum_variable_value + (2 * maximum_variable_value * x[i]) / (2**variable_length - 1)

    return x


def evaluate_individual(x): # objective funtion
    fitness = sim(x)
    return fitness


def initialize_population(population_size, number_of_genes):
    population = np.zeros((population_size, number_of_genes), dtype=int)

    for i in range(population_size):
        for j in range(number_of_genes):
            r = np.random.rand()
            if r < 0.5:
                population[i, j] = 0
            else:
                population[i, j] = 1

    return population


def mutate(individual, mutation_probability):
    n_genes = len(individual)
    mutated_individual = np.copy(individual)

    for i in range(n_genes):
        r = np.random.rand()
        if r < mutation_probability:
            mutated_individual[i] = 1 - individual[i]

    return mutated_individual


def run_function_optimization(population_size, number_of_genes, number_of_variables, maximum_variable_value,
                              tournament_size, tournament_probability, crossover_probability, mutation_probability,
                              number_of_generations):
    maximum_fitness_best = 0
    best_variable_values_best = np.zeros(number_of_variables)
    population = initialize_population(population_size, number_of_genes)

    for generation in range(number_of_generations):
        maximum_fitness = 0.0
        fitness_list = np.zeros(population_size)
        for i in range(population_size):
            chromosome = population[i, :]
            variable_values = decode_chromosome(chromosome, number_of_variables, maximum_variable_value)
            fitness_list[i] = evaluate_individual(variable_values)
            if fitness_list[i] > maximum_fitness:
                maximum_fitness = fitness_list[i]
                i_best_individual = i
                best_variable_values = variable_values
            
            if fitness_list[i] > maximum_fitness_best:
                maximum_fitness_best = fitness_list[i]
                best_variable_values_best = variable_values

        temporary_population = population
        for i in range(0, population_size, 2):
            i1 = tournament_select(fitness_list, tournament_probability, tournament_size)
            i2 = tournament_select(fitness_list, tournament_probability, tournament_size)
            r = np.random.rand()
            if r < crossover_probability:
                individual1 = population[i1, :]
                individual2 = population[i2, :]
                new_individual_pair = crossover(individual1, individual2)
                temporary_population[i, :] = new_individual_pair[0, :]
                temporary_population[i+1, :] = new_individual_pair[1, :]
            else:
                temporary_population[i, :] = population[i1, :]
                temporary_population[i+1, :] = population[i2, :]

        temporary_population[0, :] = population[i_best_individual, :]
        for i in range(1, population_size):
            temp_individual = mutate(temporary_population[i, :], mutation_probability)
            temporary_population[i, :] = temp_individual

        population = temporary_population
        print('generation:', generation, 'maximum_fitness:', maximum_fitness_best, end='\r')
        np.save('best_plan.npy', np.array(best_variable_values_best))
        np.save('generation.npy', np.array(generation))

    return maximum_fitness_best, best_variable_values_best


def approx_grad(plan, eta):
    grad = (sim(plan + eta) - sim(plan)) / eta
    return grad


def grad_descent(plan, eta, n_its):
    tot_dists = [0]
    best_plan = plan.copy()

    for t in range(n_its):

        grad = approx_grad(plan, eta)
        alpha = eta
        plan = plan - alpha*grad
        dist = sim(plan)

        if tot_dists[-1] < dist:
            tot_dists.append(dist)
            best_plan = plan.copy()
        else:
            tot_dists.append(tot_dists[-1])

        print('t =', t, 'max dist:', np.max(tot_dists), end='\r') if t%10 == 0 else None

    return best_plan, tot_dists


def random_search(n_its):
    tot_dists = [0]
    best_plan = None

    for t in range(n_its):

        plan = np.random.uniform(-1, 1, 40)
        dist = sim(plan)

        if tot_dists[-1] < dist:
            tot_dists.append(dist)
            best_plan = plan.copy()
        else:
            tot_dists.append(tot_dists[-1])

        print('t =', t, 'max dist:', np.max(tot_dists), end='\r') if t%10 == 0 else None
    
    return best_plan, tot_dists


if __name__ == "__main__":

    n_its = 1000
    eta = 0.1
    samples = np.linspace(0, n_its, n_its+1)
    plan = np.random.uniform(-1, 1, 40)

    best_plan, tot_dists = random_search(n_its)
    print('\nRandom search: \nbest dist:', tot_dists[-1], '\nbest plan:', best_plan)
    best_plan, tot_dists = grad_descent(plan, eta, n_its)
    print('\nGradient descent: \nbest dist:', tot_dists[-1], '\nbest plan:', best_plan)

    population_size = 500
    maximum_variable_value = 1
    number_of_genes = 50
    number_of_variables = 40

    tournament_size = 3
    tournament_probability = 0.785
    crossover_probability = 0.8
    mutation_probability = 0.02
    number_of_generations = 100

    maximum_fitness, best_plan = run_function_optimization(
        population_size, number_of_genes, number_of_variables, maximum_variable_value,
        tournament_size, tournament_probability, crossover_probability, mutation_probability,
        number_of_generations
    )
    print('\nEvolutionary algorithm: \nbest dist:', maximum_fitness, '\nbest plan:', best_plan)

    best_plan = [-1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1]

    dist = sim(best_plan)
    print('Best dist;', dist)
    print('Best plan:', best_plan)

\end{lstlisting}

\end{document}
